<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Junhyeok Kim</title>

  <meta name="author" content="Junhyeok Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <!-- <link rel="stylesheet" type="text/css" href="stylesheet.css"> -->

  <style>
    body {
      font-family: 'Georgia', Helvetica, Arial, sans-serif; background-color: #F4F6FC;
    }

    :root {
      --img-col-width: 30%;
    }
  </style>

  <meta name="google-site-verification" content="BEkgUM0Mpz-mJ5upo7tnym3o19K08UUenk2cZr3ezCc" />
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center; font-size: 36px;">
                    Junhyeok Kim
                  </p>
                  <p>
                    Hello! I'm a Ph.D. student at <a href="https://micv.yonsei.ac.kr/home">MICV Lab</a>, and being
                    advised by
                    Prof. <a href="https://scholar.google.com/citations?user=d4WCQbUAAAAJ&hl=en">Seong Jae Hwang</a>.
                    I'm currently interested in mechanistic interpretability, vision-language models, and a little
                    bit of medical imaging! <br>
                    Recently, <a href="https://arxiv.org/abs/2509.17401">my first first-author paper</a>, which interprets ViT features and uncovers circuits to understand the model’s underlying mechanisms, has been accepted to NeurIPS ’25. <br>
                    I am actively looking for internship opportunities. Please feel free to reach out!
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:timespt@yonsei.ac.kr">Email</a> &nbsp;/&nbsp;
                    <!-- <a href="data/Junhyeok-Kim-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                    <a href="https://scholar.google.com/citations?hl=en&user=OjGkP-8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/junhyeok-kim-776378311/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/timesplutic">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:25%;max-width:25%">
                  <a href="images/me.jpg">
                    <img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 5%; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.2);"
                      alt="profile photo" src="images/me.jpg" class="hoverZoomLink">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>News</h2>
                  <p>
                    ENTER HERE
                  </p>
                </td>
              </tr>
            </tbody>
          </table> -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    Currently, my primary research interest lies in Mechanistic Interpretability (MI). By leveraging MI,
                    we can understand what capabilities an AI model specializes in and what capabilities it requires. I
                    believe that this deep understanding of AI models will ultimately serve as a major foundation for
                    advancing towards Artificial General Intelligence (AGI).
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:16px;width: var(--img-col-width);vertical-align:middle">
                  <img src="images/figs/lvlm_flow.png" alt="blind-date"
                    style="max-width: 100%; height: auto; display: block; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
                </td>
                <td style="padding:8px;width: calc(100% - var(--img-col-width));vertical-align:middle">
                  <a href="https://arxiv.org/abs/2509.17588">
                    <span class="papertitle">Interpreting Attention Heads for Image-to-Text Information Flow in Large
                      Vision-Language Models</span>
                  </a>
                  <br>
                  Jinyeong Kim, Seil Kang, Jiwoo Park, <strong>Junhyeok Kim</strong>, Seong Jae Hwang
                  <br>
                  <em>NeurIPS MechInterp Workshop 2025 <span style="color: red;">Spotlight!</span></em>
                  <p>The image-to-text transfer in LVLMs depends on specialized attention head groups that are
                    determined by the semantic content of the image.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:16px;width: var(--img-col-width);vertical-align:middle">
                  <img src="images/figs/rrm.png" alt="blind-date"
                    style="max-width: 100%; height: auto; display: block; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
                </td>
                <td style="padding:8px;width: calc(100% - var(--img-col-width));vertical-align:middle">
                  <a href="https://arxiv.org/abs/2509.17401">
                    <span class="papertitle">Interpreting vision transformers via residual replacement model</span>
                  </a>
                  <br>
                  Jinyeong Kim*, <strong>Junhyeok Kim*</strong>, Yumin Shim, Joohyeok Kim, Sunyoung Jung, Seong Jae
                  Hwang
                  <br>
                  <em>NeurIPS 2025</em>
                  <p>Residual replacement model explains end-to-end decision-making process of vision transformers in
                    human-understandable scale.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:16px;width: var(--img-col-width);vertical-align:middle">
                  <img src="images/figs/bat.png" alt="blind-date"
                    style="max-width: 100%; height: auto; display: block; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
                </td>
                <td style="padding:8px;width: calc(100% - var(--img-col-width));vertical-align:middle">
                  <a href="https://arxiv.org/abs/2506.04288">
                    <span class="papertitle">Backbone Augmented Training for Adaptations</span>
                  </a>
                  <br>
                  Jae Wan Park, <strong>Junhyeok Kim</strong>, Youngjun Jun, Hyunah Ko, Seong Jae Hwang
                  <br>
                  <em>arXiv 2025</em>
                  <p>To solve the problem of scarce adaptation data, the pre-training data of the backbone model can be
                    selectively utilized to augment the adaptation dataset.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:16px;width: var(--img-col-width);vertical-align:middle">
                  <img src="images/figs/localization_head.png" alt="blind-date"
                    style="max-width: 100%; height: auto; display: block; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
                </td>
                <td style="padding:8px;width: calc(100% - var(--img-col-width));vertical-align:middle">
                  <a href="https://arxiv.org/abs/2503.06287">
                    <span class="papertitle">Your large vision-language model only needs a few attention heads for
                      visual grounding</span>
                  </a>
                  <br>
                  Seil Kang, Jinyeong Kim, <strong>Junhyeok Kim</strong>, Seong Jae Hwang
                  <br>
                  <em>CVPR 2025 <span style="color: red;">Highlight!</span></em>
                  <p>A few attention heads in frozen LVLMs demonstrate strong visual grounding capabilities. These
                    "localization heads" immediately enable training-free detection and segmentation.</p>
                </td>
              </tr>


              <tr>
                <td style="padding:16px;width: var(--img-col-width);vertical-align:middle">
                  <img src="images/figs/var.png" alt="blind-date"
                    style="max-width: 100%; height: auto; display: block; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
                </td>
                <td style="padding:8px;width: calc(100% - var(--img-col-width));vertical-align:middle">
                  <a href="https://arxiv.org/abs/2503.03321">
                    <span class="papertitle">See what you are told: Visual attention sink in large multimodal
                      models</span>
                  </a>
                  <br>
                  Seil Kang*, Jinyeong Kim*, <strong>Junhyeok Kim</strong>, Seong Jae Hwang
                  <br>
                  <em>ICLR 2025</em>
                  <p>Large multimodal models consistently see irrelevant parts of the input. Our work demystifies this
                    phenomenon, dubbed "visual attention sink," and proposes a simple mitigation strategy.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:16px;width: var(--img-col-width);vertical-align:middle">
                  <img src="images/figs/wolf.png" alt="blind-date"
                    style="max-width: 100%; height: auto; display: block; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
                </td>
                <td style="padding:8px;width: calc(100% - var(--img-col-width));vertical-align:middle">
                  <a href="https://arxiv.org/abs/2403.15456">
                    <span class="papertitle">WoLF: Wide-scope Large Language Model Framework for CXR
                      Understanding</span>
                  </a>
                  <br>
                  Seil Kang, <strong>Junhyeok Kim</strong>, Donghyun Kim, Hyo Kyung Lee, Seong Jae Hwang
                  <br>
                  <em>arXiv 2024</em>
                  <p>WOLF is a novel Large Language Model framework for Chest X-ray understanding that integrates
                    patient Electronic Health Records (EHR).</p>
                </td>
              </tr>


            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Miscellaneous</h2>
                  <p>
                    Need another <a href="https://junhyeok.kim/">Junhyeok Kim</a>? He's just one click away! (He is my mate as well as my namesake.)
                    I really love <a href="images/topster_2024.png">music</a> (2024). <br>
                    <!-- I still love <a href="images/topster_2025.png">music</a> (2025). <br> -->
                  </p>
                </td>
              </tr>
            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    This website is built based on <a href="https://jonbarron.info/">Jon Barron</a>'s personal website.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
